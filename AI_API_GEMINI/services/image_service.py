import json
import asyncio
import os
import base64
from pathlib import Path
from dotenv import load_dotenv
from fastapi import HTTPException
from google import genai
from google.genai import types
from services.schemas import DreamImageRequest, DreamImageResponse, GeneratedImage

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (í˜„ì¬ íŒŒì¼ ê¸°ì¤€ ìƒìœ„ í´ë”ì˜ .env)
ENV_PATH = Path(__file__).resolve().parent.parent / ".env"
load_dotenv(ENV_PATH, override=True)

# Gemini API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œë§Œ ì°¸ì¡°)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
gemini_client = genai.Client(api_key=GEMINI_API_KEY)


async def enhance_dream_prompt_for_image(dream_content: str) -> str:
    """
    LLM(gpt-5-mini)ì„ ì‚¬ìš©í•˜ì—¬ ê¿ˆ ì¼ê¸° ë³¸ë¬¸ì„ ì´ë¯¸ì§€ ìƒì„±ì— ì í•©í•œ ì‹œê°ì  ë¬˜ì‚¬ë¡œ ë³€í™˜
    
    Args:
        dream_content: ì‚¬ìš©ìì˜ ê¿ˆ ì¼ê¸° ë³¸ë¬¸ (í•œê¸€)
    
    Returns:
        ì´ë¯¸ì§€ ìƒì„±ì— ìµœì í™”ëœ ì˜ì–´ ì‹œê°ì  ë¬˜ì‚¬
    """
    
    system_prompt = """You are an expert at converting dream diary entries into vivid visual descriptions for image generation AI.

CRITICAL RULES:
1. Extract ONLY the visual elements from the dream (scenes, objects, characters, atmosphere, colors, lighting)
2. Describe them in a cinematic, painterly way suitable for image AI
3. NEVER include any text, words, letters, numbers, or symbols in your description
4. Convert any mentioned text elements (signs, letters, documents, messages) into pure visual objects
   - Example: "a letter saying 'I love you'" â†’ "a hand holding a folded paper with a red heart seal"
   - Example: "a sign that said 'Welcome'" â†’ "a wooden signboard at an entrance"
5. Remove abstract concepts, emotions, and keep only visualizable elements
6. Output should be 2-4 sentences, purely descriptive, NO story narration
7. Write ONLY in English for better image generation compatibility
8. Focus on: composition, lighting, colors, mood, atmosphere, visual details
9. ONLY output the visual description, nothing else. No explanations, no prefixes."""

    user_prompt = f"""Convert this dream diary entry into a visual description for image generation:

Dream diary entry:
{dream_content}

Example conversions for reference:
- "ì˜¤ëŠ˜ ê¿ˆì—ì„œ í• ë¨¸ë‹ˆ ëŒ ë§ˆë‹¹ì— ìˆì—ˆëŠ”ë° ê°‘ìê¸° í•˜ëŠ˜ì—ì„œ ê¸ˆìƒ‰ ë¹„ê°€ ë‚´ë ¸ì–´." â†’ "An elderly Korean traditional courtyard house (hanok) at twilight, golden rain falling from a mystical purple-pink sky, warm ethereal lighting, magical atmosphere"
- "ì‹œí—˜ ê²°ê³¼í‘œì— '100ì 'ì´ë¼ê³  ì í˜€ìˆì—ˆê³  ì¹œêµ¬ê°€ ì¶•í•˜í•´ì¤¬ì–´" â†’ "A joyful student holding a glowing paper in a bright classroom, a friend celebrating beside them with raised arms, warm golden sunlight streaming through large windows"

Now provide ONLY the visual description (2-4 sentences in English):"""

    try:
        # Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ë³€í™˜
        full_prompt = f"{system_prompt}\n\n{user_prompt}"
        
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: gemini_client.models.generate_content(
                model="gemini-2.5-flash",
                contents=full_prompt
            )
        )
        
        enhanced_prompt = response.text.strip() if response.text else ""
        
        if enhanced_prompt:
            print(f"âœ¨ í”„ë¡¬í”„íŠ¸ ë³€í™˜ ì™„ë£Œ (gemini-2.5-flash): {enhanced_prompt[:100]}...")
            return enhanced_prompt
        
        print("âš ï¸ í”„ë¡¬í”„íŠ¸ ë³€í™˜ ê²°ê³¼ ì—†ìŒ, ì›ë³¸ ì‚¬ìš©")
        return dream_content
        
    except Exception as e:
        print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}, ì›ë³¸ ì‚¬ìš©")
        return dream_content


async def process_dream_image(request: DreamImageRequest) -> DreamImageResponse:
    """
    ê¿ˆ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
    Gemini 2.0 Flash Exp Image Generation ëª¨ë¸ ì‚¬ìš©
    """
    
    # ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ í‚¤ì›Œë“œ ì •ì˜ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” 4ê°€ì§€ ìŠ¤íƒ€ì¼)
    STYLE_PROMPTS = {
        "ëª½í™˜ì ": "ëª½í™˜ì ì´ê³  ì‹ ë¹„ë¡œìš´ ë¶„ìœ„ê¸°, dreamlike, mystical atmosphere, ethereal, soft glow",
        "ìˆ˜ì±„í™”": "ë¶€ë“œëŸ¬ìš´ ìˆ˜ì±„í™” ìŠ¤íƒ€ì¼, watercolor painting style, soft colors, artistic, delicate brushstrokes",
        "ì• ë‹ˆë©”ì´ì…˜": "ì• ë‹ˆë©”ì´ì…˜ ì‘í™” ìŠ¤íƒ€ì¼, anime style, vivid colors, 2D rendering, Japanese animation",
        "íŒíƒ€ì§€": "íŒíƒ€ì§€ ì•„íŠ¸ ìŠ¤íƒ€ì¼, fantasy art, epic, magical, detailed, enchanted atmosphere",
    }

    # ì„ íƒëœ ìŠ¤íƒ€ì¼ì— ë§ëŠ” í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: ëª½í™˜ì )
    style_keyword = STYLE_PROMPTS.get(request.style, STYLE_PROMPTS["ëª½í™˜ì "])

    # âœ¨ 1ë‹¨ê³„: LLMì„ ì‚¬ìš©í•˜ì—¬ ê¿ˆ ì¼ê¸°ë¥¼ ì‹œê°ì  ë¬˜ì‚¬ë¡œ ë³€í™˜
    print(f"ğŸ”„ ê¿ˆ ì¼ê¸°ë¥¼ ì‹œê°ì  ë¬˜ì‚¬ë¡œ ë³€í™˜ ì¤‘... (ì›ë³¸: {request.dream_prompt[:50]}...)")
    enhanced_prompt = await enhance_dream_prompt_for_image(request.dream_prompt)
    
    # ê³ ì •ëœ í”„ë¡¬í”„íŠ¸ (í…ìŠ¤íŠ¸/ì›Œí„°ë§ˆí¬ ê¸ˆì§€ - ê°•í™” ë²„ì „)
    DEFAULT_PROMPT = (
        "Generate a purely visual image with ABSOLUTELY NO TEXT, NO LETTERS, NO WORDS, NO NUMBERS, NO SYMBOLS, NO WATERMARKS, NO CAPTIONS, NO SUBTITLES, NO SIGNATURES, NO LOGOS anywhere in the image. "
        "This is extremely important: the image must contain ZERO text elements of any kind. "
        "Visualize the following dream content as a cinematic scene. "
        f"Style: {style_keyword}. Square aspect ratio. "
        "Dream content: "
    )
    
    # âœ¨ 2ë‹¨ê³„: ë³€í™˜ëœ í”„ë¡¬í”„íŠ¸ë¡œ ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¡°í•©
    full_prompt = f"{DEFAULT_PROMPT}{enhanced_prompt}"
    
    print(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì¤‘... (Enhanced Prompt: {enhanced_prompt[:80]}..., Style: {request.style})")
    
    try:
        # Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, 
            lambda: gemini_client.models.generate_content(
                model="gemini-2.0-flash-exp-image-generation",
                contents=full_prompt,
                config=types.GenerateContentConfig(
                    response_modalities=["TEXT", "IMAGE"]
                )
            )
        )
        
        generated_images = []
        model_text = None
        
        # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì¶”ì¶œ
        if response.candidates and len(response.candidates) > 0:
            candidate = response.candidates[0]
            if candidate.content and candidate.content.parts:
                for part in candidate.content.parts:
                    # í…ìŠ¤íŠ¸ íŒŒíŠ¸ ì²˜ë¦¬
                    if part.text:
                        model_text = part.text
                        print(f"[ëª¨ë¸ ì‘ë‹µ í…ìŠ¤íŠ¸]: {model_text}")
                    
                    # ì´ë¯¸ì§€ íŒŒíŠ¸ ì²˜ë¦¬
                    if part.inline_data:
                        mime_type = part.inline_data.mime_type or 'image/png'
                        # inline_data.dataëŠ” bytes íƒ€ì…ì´ë¯€ë¡œ base64ë¡œ ì¸ì½”ë”©
                        image_data_b64 = base64.b64encode(part.inline_data.data).decode('utf-8')
                        
                        generated_images.append(GeneratedImage(
                            image_data=image_data_b64,
                            mime_type=mime_type
                        ))
                        print(f"[ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ]: {mime_type}")
        
        if not generated_images:
            return DreamImageResponse(
                success=True,
                message="ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜ë¨)",
                images=[],
                model_text=model_text
            )
        
        return DreamImageResponse(
            success=True,
            message=f"{len(generated_images)}ê°œì˜ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            images=generated_images,
            model_text=model_text
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
